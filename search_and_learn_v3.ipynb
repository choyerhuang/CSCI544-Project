{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xctusmJ6BZ6_"
      },
      "source": [
        "# Scaling Test-Time Compute for Longer Thinking in LLMs\n",
        "\n",
        "This notebook is originally based on a huggingface [cookbook](https://github.com/huggingface/cookbook/blob/main/notebooks/en/search_and_learn.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcbzN_vN_-AB"
      },
      "source": [
        "❗️This notebook can only perform inference but not benchmark a searching strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASKzOmOlr0fI"
      },
      "source": [
        "This needs T4 GPU and is only tested with `config.n=4`. `config.n=8` causes OOM. \\\n",
        "Execution Time of each query with these settings:\n",
        "- best_of_n: 1 mins\n",
        "- beam_search: 5 mins\n",
        "- dvts: 2 mins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy8xg9GLs5jy"
      },
      "source": [
        "❗️Huge amount of time is needed for `pip install` and downloading models in every new RUNTIME. If any error occurs, restart the SESSION."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twKCzVIg71Xa"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKdHzQUXGjAh"
      },
      "source": [
        "Since Colab comes with many pre-installed packages, leading to difficult-to-resolve version conflicts, we install dependencies in a local virtual environment and freeze them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vniSZihLpl0y"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo \"\n",
        "accelerate==1.5.2\n",
        "aiohappyeyeballs==2.6.1\n",
        "aiohttp==3.11.14\n",
        "aiosignal==1.3.2\n",
        "annotated-types==0.7.0\n",
        "antlr4-python3-runtime==4.7.2\n",
        "anyio==4.9.0\n",
        "attrs==25.3.0\n",
        "certifi==2025.1.31\n",
        "charset-normalizer==3.4.1\n",
        "click==8.1.8\n",
        "cloudpickle==3.1.1\n",
        "datasets==3.5.0\n",
        "dill==0.3.8\n",
        "diskcache==5.6.3\n",
        "distro==1.9.0\n",
        "einops==0.8.1\n",
        "fastapi==0.115.12\n",
        "filelock==3.18.0\n",
        "frozenlist==1.5.0\n",
        "fsspec==2024.12.0\n",
        "gguf==0.10.0\n",
        "h11==0.14.0\n",
        "hf_transfer==0.1.9\n",
        "httpcore==1.0.7\n",
        "httptools==0.6.4\n",
        "httpx==0.28.1\n",
        "huggingface-hub==0.29.3\n",
        "idna==3.10\n",
        "importlib_metadata==8.6.1\n",
        "iniconfig==2.1.0\n",
        "interegular==0.3.3\n",
        "isort==6.0.1\n",
        "Jinja2==3.1.6\n",
        "jiter==0.9.0\n",
        "jsonschema==4.23.0\n",
        "jsonschema-specifications==2024.10.1\n",
        "lark==1.2.2\n",
        "latex2sympy2==1.9.1\n",
        "llvmlite==0.44.0\n",
        "lm-format-enforcer==0.10.6\n",
        "MarkupSafe==3.0.2\n",
        "mistral_common==1.5.4\n",
        "mpmath==1.3.0\n",
        "msgpack==1.1.0\n",
        "msgspec==0.19.0\n",
        "multidict==6.2.0\n",
        "multiprocess==0.70.16\n",
        "nest-asyncio==1.6.0\n",
        "networkx==3.4.2\n",
        "numba==0.61.0\n",
        "numpy==1.26.4\n",
        "nvidia-ml-py==12.570.86\n",
        "openai==1.69.0\n",
        "opencv-python-headless==4.11.0.86\n",
        "outlines==0.0.46\n",
        "packaging==24.2\n",
        "pandas==2.2.3\n",
        "partial-json-parser==0.2.1.1.post5\n",
        "Pebble==5.1.1\n",
        "pillow==11.1.0\n",
        "pluggy==1.5.0\n",
        "prometheus-fastapi-instrumentator==7.1.0\n",
        "prometheus_client==0.21.1\n",
        "propcache==0.3.1\n",
        "protobuf==6.30.2\n",
        "psutil==7.0.0\n",
        "py-cpuinfo==9.0.0\n",
        "pyairports==2.1.1\n",
        "pyarrow==19.0.1\n",
        "pycountry==24.6.1\n",
        "pydantic==2.11.1\n",
        "pydantic_core==2.33.0\n",
        "pytest==8.3.5\n",
        "python-dateutil==2.9.0.post0\n",
        "python-dotenv==1.1.0\n",
        "pytz==2025.2\n",
        "PyYAML==6.0.2\n",
        "pyzmq==26.3.0\n",
        "ray==2.44.1\n",
        "referencing==0.36.2\n",
        "regex==2024.11.6\n",
        "requests==2.32.3\n",
        "rpds-py==0.24.0\n",
        "ruff==0.11.2\n",
        "safetensors==0.5.3\n",
        "sentencepiece==0.2.0\n",
        "six==1.17.0\n",
        "sniffio==1.3.1\n",
        "starlette==0.46.1\n",
        "sympy==1.13.3\n",
        "tiktoken==0.9.0\n",
        "tokenizers==0.21.1\n",
        "torch==2.4.0\n",
        "torchvision==0.19.0\n",
        "tqdm==4.67.1\n",
        "transformers==4.50.3\n",
        "typing-inspection==0.4.0\n",
        "typing_extensions==4.13.0\n",
        "tzdata==2025.2\n",
        "urllib3==2.3.0\n",
        "uvicorn==0.34.0\n",
        "uvloop==0.21.0\n",
        "vllm==0.6.3\n",
        "watchfiles==1.0.4\n",
        "websockets==15.0.1\n",
        "word2number==1.1\n",
        "xxhash==3.5.0\n",
        "yarl==1.18.3\n",
        "zipp==3.21.0\n",
        "\" > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0XO0VwIHQyx"
      },
      "source": [
        "❗️This ends with multiple errors; just ignore them, as we are not using those packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Uhn86fNFtw0",
        "outputId": "5c9da73d-ecee-42f9-bb71-829364fbe054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate==1.5.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.1)\n",
            "Collecting aiohttp==3.11.14 (from -r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.11.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: aiosignal==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
            "Collecting antlr4-python3-runtime==4.7.2 (from -r requirements.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: attrs==25.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (25.3.0)\n",
            "Requirement already satisfied: certifi==2025.1.31 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle==3.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.1.1)\n",
            "Collecting datasets==3.5.0 (from -r requirements.txt (line 14))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill==0.3.8 (from -r requirements.txt (line 15))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting diskcache==5.6.3 (from -r requirements.txt (line 16))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (1.9.0)\n",
            "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (0.8.1)\n",
            "Collecting fastapi==0.115.12 (from -r requirements.txt (line 19))\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: filelock==3.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (3.18.0)\n",
            "Requirement already satisfied: frozenlist==1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.5.0)\n",
            "Collecting fsspec==2024.12.0 (from -r requirements.txt (line 22))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting gguf==0.10.0 (from -r requirements.txt (line 23))\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (0.14.0)\n",
            "Collecting hf_transfer==0.1.9 (from -r requirements.txt (line 25))\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting httpcore==1.0.7 (from -r requirements.txt (line 26))\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting httptools==0.6.4 (from -r requirements.txt (line 27))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.28.1)\n",
            "Collecting huggingface-hub==0.29.3 (from -r requirements.txt (line 29))\n",
            "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (3.10)\n",
            "Requirement already satisfied: importlib_metadata==8.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (8.6.1)\n",
            "Requirement already satisfied: iniconfig==2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.1.0)\n",
            "Collecting interegular==0.3.3 (from -r requirements.txt (line 33))\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting isort==6.0.1 (from -r requirements.txt (line 34))\n",
            "  Downloading isort-6.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (3.1.6)\n",
            "Requirement already satisfied: jiter==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (0.9.0)\n",
            "Requirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (4.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications==2024.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (2024.10.1)\n",
            "Collecting lark==1.2.2 (from -r requirements.txt (line 39))\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting latex2sympy2==1.9.1 (from -r requirements.txt (line 40))\n",
            "  Downloading latex2sympy2-1.9.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llvmlite==0.44.0 (from -r requirements.txt (line 41))\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting lm-format-enforcer==0.10.6 (from -r requirements.txt (line 42))\n",
            "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (3.0.2)\n",
            "Collecting mistral_common==1.5.4 (from -r requirements.txt (line 44))\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (1.3.0)\n",
            "Requirement already satisfied: msgpack==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 46)) (1.1.0)\n",
            "Collecting msgspec==0.19.0 (from -r requirements.txt (line 47))\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting multidict==6.2.0 (from -r requirements.txt (line 48))\n",
            "  Downloading multidict-6.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting multiprocess==0.70.16 (from -r requirements.txt (line 49))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 50)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (3.4.2)\n",
            "Collecting numba==0.61.0 (from -r requirements.txt (line 52))\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 53))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py==12.570.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 54)) (12.570.86)\n",
            "Collecting openai==1.69.0 (from -r requirements.txt (line 55))\n",
            "  Downloading openai-1.69.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: opencv-python-headless==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (4.11.0.86)\n",
            "Collecting outlines==0.0.46 (from -r requirements.txt (line 57))\n",
            "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (24.2)\n",
            "Collecting pandas==2.2.3 (from -r requirements.txt (line 59))\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting partial-json-parser==0.2.1.1.post5 (from -r requirements.txt (line 60))\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting Pebble==5.1.1 (from -r requirements.txt (line 61))\n",
            "  Downloading pebble-5.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 62)) (11.1.0)\n",
            "Requirement already satisfied: pluggy==1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 63)) (1.5.0)\n",
            "Collecting prometheus-fastapi-instrumentator==7.1.0 (from -r requirements.txt (line 64))\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: prometheus_client==0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 65)) (0.21.1)\n",
            "Requirement already satisfied: propcache==0.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 66)) (0.3.1)\n",
            "Collecting protobuf==6.30.2 (from -r requirements.txt (line 67))\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting psutil==7.0.0 (from -r requirements.txt (line 68))\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 69)) (9.0.0)\n",
            "Collecting pyairports==2.1.1 (from -r requirements.txt (line 70))\n",
            "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow==19.0.1 (from -r requirements.txt (line 71))\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pycountry==24.6.1 (from -r requirements.txt (line 72))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic==2.11.1 (from -r requirements.txt (line 73))\n",
            "  Downloading pydantic-2.11.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.33.0 (from -r requirements.txt (line 74))\n",
            "  Downloading pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pytest==8.3.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 75)) (8.3.5)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 76))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-dotenv==1.1.0 (from -r requirements.txt (line 77))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 78)) (2025.2)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 79)) (6.0.2)\n",
            "Collecting pyzmq==26.3.0 (from -r requirements.txt (line 80))\n",
            "  Downloading pyzmq-26.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting ray==2.44.1 (from -r requirements.txt (line 81))\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: referencing==0.36.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 82)) (0.36.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 83)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 84)) (2.32.3)\n",
            "Requirement already satisfied: rpds-py==0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 85)) (0.24.0)\n",
            "Collecting ruff==0.11.2 (from -r requirements.txt (line 86))\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: safetensors==0.5.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 87)) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 88)) (0.2.0)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 89)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 90)) (1.3.1)\n",
            "Collecting starlette==0.46.1 (from -r requirements.txt (line 91))\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting sympy==1.13.3 (from -r requirements.txt (line 92))\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tiktoken==0.9.0 (from -r requirements.txt (line 93))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers==0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 94)) (0.21.1)\n",
            "Collecting torch==2.4.0 (from -r requirements.txt (line 95))\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.19.0 (from -r requirements.txt (line 96))\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 97)) (4.67.1)\n",
            "Collecting transformers==4.50.3 (from -r requirements.txt (line 98))\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: typing-inspection==0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 99)) (0.4.0)\n",
            "Collecting typing_extensions==4.13.0 (from -r requirements.txt (line 100))\n",
            "  Downloading typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 101)) (2025.2)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 102)) (2.3.0)\n",
            "Collecting uvicorn==0.34.0 (from -r requirements.txt (line 103))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvloop==0.21.0 (from -r requirements.txt (line 104))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting vllm==0.6.3 (from -r requirements.txt (line 105))\n",
            "  Downloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting watchfiles==1.0.4 (from -r requirements.txt (line 106))\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets==15.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 107)) (15.0.1)\n",
            "Collecting word2number==1.1 (from -r requirements.txt (line 108))\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xxhash==3.5.0 (from -r requirements.txt (line 109))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl==1.18.3 (from -r requirements.txt (line 110))\n",
            "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp==3.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 111)) (3.21.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0->-r requirements.txt (line 95))\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting xformers==0.0.27.post2 (from vllm==0.6.3->-r requirements.txt (line 105))\n",
            "  Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r requirements.txt (line 95)) (12.5.82)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'aiohttp' candidate (version 3.11.14 at https://files.pythonhosted.org/packages/51/66/30b217d0de5584650340025a285f1d0abf2039e5a683342891e84f250da9/aiohttp-3.11.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/aiohttp/) (requires-python:>=3.9))\n",
            "Reason for being yanked: Regression: https://github.com/aio-libs/aiohttp/issues/10617\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading aiohttp-3.11.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading isort-6.0.1-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latex2sympy2-1.9.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.69.0-py3-none-any.whl (599 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading pebble-5.1.1-py3-none-any.whl (34 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.1-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pyzmq-26.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (867 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl (193.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.1/344.1 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, word2number\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.7.2-py3-none-any.whl size=140930 sha256=88142b4f88d5c5bb8c0dbb234884f58c0ed3146c8e81c4c859481099c838fb05\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/f4/c7/71f768e561b9cc8bce3160d1229728d0d77fd5fd6d4f5d960b\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=d4c5ef4d108c6457a3626a1f063f0e3978277aca776364bafe35fec830d8178d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built antlr4-python3-runtime word2number\n",
            "Installing collected packages: word2number, pyairports, antlr4-python3-runtime, xxhash, uvloop, uvicorn, typing_extensions, triton, sympy, ruff, pyzmq, python-dotenv, python-dateutil, pycountry, pyarrow, psutil, protobuf, Pebble, partial-json-parser, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multidict, msgspec, llvmlite, lark, isort, interegular, httptools, httpcore, hf_transfer, fsspec, diskcache, dill, yarl, tiktoken, pydantic_core, pandas, nvidia-cusolver-cu12, nvidia-cudnn-cu12, numba, multiprocess, latex2sympy2, huggingface-hub, gguf, watchfiles, torch, starlette, pydantic, aiohttp, xformers, transformers, torchvision, prometheus-fastapi-instrumentator, openai, lm-format-enforcer, fastapi, ray, mistral_common, datasets, outlines, vllm\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.4.3\n",
            "    Uninstalling multidict-6.4.3:\n",
            "      Successfully uninstalled multidict-6.4.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.8\n",
            "    Uninstalling httpcore-1.0.8:\n",
            "      Successfully uninstalled httpcore-1.0.8\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.19.0\n",
            "    Uninstalling yarl-1.19.0:\n",
            "      Successfully uninstalled yarl-1.19.0\n",
            "  Attempting uninstall: pydantic_core\n",
            "    Found existing installation: pydantic_core 2.33.1\n",
            "    Uninstalling pydantic_core-2.33.1:\n",
            "      Successfully uninstalled pydantic_core-2.33.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.30.2\n",
            "    Uninstalling huggingface-hub-0.30.2:\n",
            "      Successfully uninstalled huggingface-hub-0.30.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.75.0\n",
            "    Uninstalling openai-1.75.0:\n",
            "      Successfully uninstalled openai-1.75.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.2 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.2 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.2 which is incompatible.\n",
            "wandb 0.19.9 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.30.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.30.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.88.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0,>=3.20.2, but you have protobuf 6.30.2 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pebble-5.1.1 aiohttp-3.11.14 antlr4-python3-runtime-4.7.2 datasets-3.5.0 dill-0.3.8 diskcache-5.6.3 fastapi-0.115.12 fsspec-2024.12.0 gguf-0.10.0 hf_transfer-0.1.9 httpcore-1.0.7 httptools-0.6.4 huggingface-hub-0.29.3 interegular-0.3.3 isort-6.0.1 lark-1.2.2 latex2sympy2-1.9.1 llvmlite-0.44.0 lm-format-enforcer-0.10.6 mistral_common-1.5.4 msgspec-0.19.0 multidict-6.2.0 multiprocess-0.70.16 numba-0.61.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 openai-1.69.0 outlines-0.0.46 pandas-2.2.3 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-6.30.2 psutil-7.0.0 pyairports-2.1.1 pyarrow-19.0.1 pycountry-24.6.1 pydantic-2.11.1 pydantic_core-2.33.0 python-dateutil-2.9.0.post0 python-dotenv-1.1.0 pyzmq-26.3.0 ray-2.44.1 ruff-0.11.2 starlette-0.46.1 sympy-1.13.3 tiktoken-0.9.0 torch-2.4.0 torchvision-0.19.0 transformers-4.50.3 triton-3.0.0 typing_extensions-4.13.0 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.6.3 watchfiles-1.0.4 word2number-1.1 xformers-0.0.27.post2 xxhash-3.5.0 yarl-1.18.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b8b13c6e48854227b851e1ed4925caed",
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "psutil",
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0YDC2_7XTm8",
        "outputId": "f1b7bd3e-7f2b-4630-fb28-0e0321aa799f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CSCI544-Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/choyerhuang/CSCI544-Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl8Vh80EHLvl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLExGBclx8PK"
      },
      "source": [
        "❗️If `ImportError: No module named sal`, restart session and start again from here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT3jH_d_XcEb",
        "outputId": "ac17ef86-2e8f-4083-b9b5-921d0a424fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CSCI544-Project\n",
            "Obtaining file:///content/CSCI544-Project\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: pebble in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: latex2sympy2==1.9.1 in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (1.9.1)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (1.1)\n",
            "Requirement already satisfied: transformers>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (4.50.3)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (0.115.12)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (0.1.9)\n",
            "Requirement already satisfied: sympy>=1.4 in /usr/local/lib/python3.11/dist-packages (from latex2sympy2==1.9.1->search-and-learn==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.7.2 in /usr/local/lib/python3.11/dist-packages (from latex2sympy2==1.9.1->search-and-learn==0.1.0) (4.7.2)\n",
            "Requirement already satisfied: vllm==0.6.3 in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (0.6.3)\n",
            "Requirement already satisfied: ruff in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (0.11.2)\n",
            "Requirement already satisfied: isort in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (8.3.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (7.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (6.30.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (3.11.14)\n",
            "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (1.69.0)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.34.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.11.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (11.1.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.10.6)\n",
            "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (4.13.0)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (26.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.19.0)\n",
            "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (8.6.1)\n",
            "Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.44.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (12.570.86)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.19.0)\n",
            "Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.0.27.post2)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm==0.6.3->search-and-learn==0.1.0) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm==0.6.3->search-and-learn==0.1.0) (24.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.5.82)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->search-and-learn==0.1.0) (0.46.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (0.29.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->search-and-learn==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->search-and-learn==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (5.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.61.0)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.36.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (24.6.1)\n",
            "Requirement already satisfied: pyairports in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.4->latex2sympy2==1.9.1->search-and-learn==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (1.18.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->vllm==0.6.3->search-and-learn==0.1.0) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2.2.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.70.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (1.17.0)\n",
            "Building wheels for collected packages: search-and-learn\n",
            "  Building editable for search-and-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for search-and-learn: filename=search_and_learn-0.1.0-0.editable-py3-none-any.whl size=8678 sha256=bc617ad45cd2f2d2751e80f89764c7ccc6950056813134fdac0a19de7650b118\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7wukhd48/wheels/5f/73/83/9b97bb726bbe8f29bc7dde852991239cf76c52b50fd1f32b62\n",
            "Successfully built search-and-learn\n",
            "Installing collected packages: search-and-learn\n",
            "  Attempting uninstall: search-and-learn\n",
            "    Found existing installation: search-and-learn 0.1.0\n",
            "    Uninstalling search-and-learn-0.1.0:\n",
            "      Successfully uninstalled search-and-learn-0.1.0\n",
            "Successfully installed search-and-learn-0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/CSCI544-Project\n",
        "!pip install -e '.[dev]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQHu9T176zh"
      },
      "source": [
        "Log in to Hugging Face to access [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct), as it is a gated model! 🗝️  \n",
        "If you haven't previously requested access, you'll need to submit a request before proceeding.\n",
        "\n",
        "⚠️ Use your USC email to register an account. When requesting access, enter \"University of Southern California\" as your affiliation and select \"Research Graduate\"; otherwise, your request will be rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2a245e39189e47c58bc046527600db2c",
            "2551e3c25d0c4d83b90e6ebc7a320846"
          ]
        },
        "id": "pnEaTlFYZF_H",
        "outputId": "ef550bc8-04b1-41ce-fc36-0809413fcb6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a245e39189e47c58bc046527600db2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX07zCTA8MWL"
      },
      "source": [
        "## 2. Setup the Large Language Model (LLM) and the Process Reward Model (PRM) 💬\n",
        "\n",
        "As illustrated in the diagram, the system consists of an LLM that generates intermediate answers based on user input, a [PRM model](https://huggingface.co/papers/2211.14275) that evaluates and scores these answers, and a search strategy that uses the PRM feedback to guide the subsequent steps in the search process until reaching the final answer.\n",
        "\n",
        "Let’s begin by initializing each model. For the LLM, we’ll use the [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) model, and for the PRM, we’ll use the [RLHFlow/Llama3.1-8B-PRM-Deepseek-Data](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data) model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkJw0x7gDJEY"
      },
      "source": [
        "![system](https://huggingface.co/datasets/HuggingFaceH4/blogpost-images/resolve/main/system.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L42axgg1uE-n"
      },
      "source": [
        "⬇️ Start again from here after **Restart session**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949,
          "referenced_widgets": [
            "894920f5f4364f42bacff410bd38a8a2",
            "6dc243152932471e8f8d29c91499e84b",
            "2c85d529894847d080f2e8e4dc87a3a5",
            "408aac5d48174285b672900f2629847c",
            "c374c51afa8e4e239f25999c718d5445",
            "fbec446655044d629512c9aaea7a2b99",
            "94171bd013df416894f7386023bb8908",
            "06e62a13cd394334968f35e823f00209",
            "25292ad9fa874a0d9638eb3cedc77f8a",
            "f896e2e50530412f81852108c075a69c",
            "c8842cbfa76d435db3f7cdb651bb3a28",
            "fa7219feb2e64fe6a94e7e057a5e3f73",
            "6e0f1b5ce6e245a4b3b5bd8151d1046e",
            "05be7fc29f5e4aa3ae607afd5206acd5",
            "b7aab0419ce74bb7b8a93fc9c21efbb3",
            "af0a03e44d774557aaf775ade950d2c9",
            "90a80ac8049f48498655b523e6d953e6",
            "c7e46a287450489d880a3e188d74a1ce",
            "4a19c51484a648e684393d3138b91456",
            "0cf216fb160749728dcd26f97164cc1f",
            "80a59194d3f248a9a3a6133aa037c5b8",
            "e5906a6dcc4e41f78bd44d64e34b5334"
          ]
        },
        "id": "MG1MolfxmZ7M",
        "outputId": "eddb9c79-46ed-4de4-c80b-5345f42edf88"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
            "No module named 'vllm._version'\n",
            "  from vllm.version import __version__ as VLLM_VERSION\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 04-19 02:25:07 config.py:1674] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 04-19 02:25:19 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=meta-llama/Llama-3.2-1B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
            "INFO 04-19 02:25:21 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 04-19 02:25:21 selector.py:115] Using XFormers backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 04-19 02:25:22 model_runner.py:1060] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
            "INFO 04-19 02:25:22 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 04-19 02:25:22 selector.py:115] Using XFormers backend.\n",
            "INFO 04-19 02:25:23 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
            "INFO 04-19 02:25:23 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "894920f5f4364f42bacff410bd38a8a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 04-19 02:25:39 model_runner.py:1071] Loading model weights took 2.3185 GB\n",
            "INFO 04-19 02:25:40 gpu_executor.py:122] # GPU blocks: 6055, # CPU blocks: 8192\n",
            "INFO 04-19 02:25:40 gpu_executor.py:126] Maximum concurrency for 8192 tokens per request: 11.83x\n",
            "INFO 04-19 02:25:43 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
            "INFO 04-19 02:25:43 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "INFO 04-19 02:26:11 model_runner.py:1530] Graph capturing finished in 28 secs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa7219feb2e64fe6a94e7e057a5e3f73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from vllm import LLM\n",
        "from sal.models.reward_models import RLHFFlow\n",
        "\n",
        "model_path=\"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "prm_path=\"RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\"\n",
        "\n",
        "llm = LLM(\n",
        "    model=model_path,\n",
        "    gpu_memory_utilization=0.5,  # Utilize 50% of GPU memory\n",
        "    enable_prefix_caching=True,  # Optimize repeated prefix computations\n",
        "    seed=42,                     # Set seed for reproducibility\n",
        "    dtype='half',\n",
        "    max_model_len=8192,\n",
        ")\n",
        "\n",
        "prm = RLHFFlow(prm_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYtPn0_V_YRx"
      },
      "source": [
        "### 2.1 Instantiate the Question, Search Strategy, and Call the Pipeline\n",
        "\n",
        "Now that we've set up the LLM and PRM, let's proceed by defining the question, selecting a search strategy to retrieve relevant information, and calling the pipeline to process the question through the models.\n",
        "\n",
        "1. **Instantiate the Question**: In this step, we define the input question that the system will answer, considering the given context.\n",
        "\n",
        "2. **Search Strategy**: The system currently supports the following search strategies: `best_of_n`, `beam_search`, and `dvts` (see diagram). For this example, we'll use `best_of_n`, but you can easily switch to any of the other strategies based on your needs. We need to define some configuration parameters for the configuration of the search strategy. You can check the full list [here](https://github.com/huggingface/search-and-learn/blob/main/src/sal/config.py).\n",
        "\n",
        "3. **Call the Pipeline**: With the question and search strategy in place, we’ll call the inference pipeline, processing the inputs through both the LLM and PRM to generate the final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSWINPerJrhm"
      },
      "source": [
        "![](https://huggingface.co/datasets/HuggingFaceH4/blogpost-images/resolve/main/search-strategies.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z69xD6i2L5a6"
      },
      "source": [
        "The first step is to clearly define the question that the system will answer. This ensures that we have a precise task for the model to tackle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "83puLxhzsOM0"
      },
      "outputs": [],
      "source": [
        "question_text = 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$'\n",
        "input_batch = {\"problem\": [question_text]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGpyzMNkAO7H"
      },
      "source": [
        "Next, we define the configuration, including parameters like the number of candidate answers `(N)`, and choose the search strategy that will be used. The search strategy dictates how we explore the potential answers. In this case, we'll use `best_of_n`.\n",
        "\n",
        "With the question and configuration in place, we use the selected search strategy to generate multiple candidate answers. These candidates are evaluated based on their relevance and quality and the final answer is returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C6s6GS16QZLV"
      },
      "outputs": [],
      "source": [
        "from sal.config import Config\n",
        "import os\n",
        "os.chdir('/content/CSCI544-Project')\n",
        "from sal.search import beam_search, best_of_n, dvts, run_dynamic_beam_search, beam_search_ev, greedy_backtrack_search\n",
        "config = Config()\n",
        "\n",
        "config.n=4 # Number of answers to generate during the search\n",
        "config.prm_batch_size=1\n",
        "config.search_batch_size=1\n",
        "\n",
        "#search_result = best_of_n(x=input_batch, config=config, llm=llm, prm=prm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsLHD_6C_15p"
      },
      "source": [
        "### 2.2 Display the Final Result\n",
        "\n",
        "Once the pipeline has processed the question through the LLM and PRM, we can display the final result. This result will be the model's output after considering the intermediate answers and scoring them using the PRM.\n",
        "\n",
        "Here's how to display the final answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "v8medbURbgdI",
        "outputId": "6b05f69b-26a9-4f0e-ed8a-bc29c24b2e90"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Step 1: Recall the conversion formulas\\nTo convert from rectangular coordinates $(x, y)$ to polar coordinates $(r, heta)$, we use the following formulas: $r = \\\\sqrt{x^2 + y^2}$ and $heta = \\\\tan^{-1}\\\\left(\\\\frac{y}{x}\\\\right)$.\\n\\n## Step 2: Plug in the values\\nGiven the point $(0, 3)$, we can substitute $x = 0$ and $y = 3$ into the formulas. This gives us $r = \\\\sqrt{0^2 + 3^2} = \\\\sqrt{9} = 3$ and $heta = \\\\tan^{-1}\\\\left(\\\\frac{3}{0}\\\\right)$.\\n\\n## Step 3: Handle the division by zero\\nSince $\\\\tan^{-1}\\\\left(\\\\frac{3}{0}\\\\right)$ is undefined, we must recognize that the point $(0, 3)$ is on the positive y-axis, which means it is at a distance of $3$ units from the origin but points in the positive y-direction, where $\\\\theta = \\\\frac{\\\\pi}{2}$.\\n\\n## Step 4: Conclude\\nTherefore, the polar coordinates of the point $(0, 3)$ are $\\\\left(3, \\\\frac{\\\\pi}{2}\\\\right)$.\\n\\nThe final answer is: $\\\\boxed{\\\\left(3, \\\\frac{\\\\pi}{2}\\\\right)}$'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_result['pred'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-8hIu05AO7J"
      },
      "source": [
        "The model’s output might include special tokens, such as `<|start_header_id|>` or `<|end_header_id|>`. To make the answer more readable, we can safely remove them before displaying it to the end user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "flbIu6-rDapM",
        "outputId": "395c99a0-8fb5-48c6-c972-afa5e6282835"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'## Step 1: Recall the conversion formulas\\nTo convert from rectangular coordinates $(x, y)$ to polar coordinates $(r, heta)$, we use the following formulas: $r = \\\\sqrt{x^2 + y^2}$ and $heta = \\\\tan^{-1}\\\\left(\\\\frac{y}{x}\\\\right)$.\\n\\n## Step 2: Plug in the values\\nGiven the point $(0, 3)$, we can substitute $x = 0$ and $y = 3$ into the formulas. This gives us $r = \\\\sqrt{0^2 + 3^2} = \\\\sqrt{9} = 3$ and $heta = \\\\tan^{-1}\\\\left(\\\\frac{3}{0}\\\\right)$.\\n\\n## Step 3: Handle the division by zero\\nSince $\\\\tan^{-1}\\\\left(\\\\frac{3}{0}\\\\right)$ is undefined, we must recognize that the point $(0, 3)$ is on the positive y-axis, which means it is at a distance of $3$ units from the origin but points in the positive y-direction, where $\\\\theta = \\\\frac{\\\\pi}{2}$.\\n\\n## Step 4: Conclude\\nTherefore, the polar coordinates of the point $(0, 3)$ are $\\\\left(3, \\\\frac{\\\\pi}{2}\\\\right)$.\\n\\nThe final answer is: $\\\\boxed{\\\\left(3, \\\\frac{\\\\pi}{2}\\\\right)}$'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatted_output = search_result['pred'][0].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\", \"\").strip()\n",
        "formatted_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZuLZNirAO7J"
      },
      "source": [
        "After removing any special tokens, we can display the final answer to the user. Since the answer is based on markdown, it can be rendered properly by displaying it as markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "P4En0qJRD0cl",
        "outputId": "2307d712-4926-43b9-f9dd-f4309ed1cea2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uCpYzAw_4o9"
      },
      "source": [
        "## 3. Assembling It All! 🧑‍🏭️\n",
        "\n",
        "Now, let's create a method that encapsulates the entire pipeline. This will allow us to easily reuse the process in future applications, making it efficient and modular.\n",
        "\n",
        "By combining the LLM, PRM, search strategy, and result display, we can simplify the workflow and ensure that it’s reusable for other tasks or questions.\n",
        "\n",
        "We simplify the workflow, ensuring that it’s reusable for different tasks or questions. Additionally, we’ll track the time spent on each method so that we can **understand the practical implications** of using each strategy and configuration.\n",
        "\n",
        "Here’s how we can structure the method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YpswbcVi37KR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def generate_with_search_and_learn(question, config, llm, prm, method='best_of_n'):\n",
        "    \"\"\"\n",
        "    Generate an answer for a given question using the search-and-learn pipeline.\n",
        "\n",
        "    Args:\n",
        "    - question (str): The input question to generate an answer for.\n",
        "    - config (Config): Configuration object containing parameters for search strategy.\n",
        "    - llm (LLM): Pretrained large language model used for generating answers.\n",
        "    - prm (RLHFFlow): Process reward model used for evaluating answers.\n",
        "    - method (str): Search strategy to use. Options are 'best_of_n', 'beam_search', 'dvts'. Default is 'best_of_n'.\n",
        "\n",
        "    Returns:\n",
        "    - str: The formatted output after processing the question.\n",
        "    \"\"\"\n",
        "    batch = {\"problem\": [question]}\n",
        "\n",
        "    start_time = time.time()\n",
        "    if method == 'best_of_n':\n",
        "      result = best_of_n(x=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'beam_search':\n",
        "      result = beam_search(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'dvts':\n",
        "      result = dvts(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'dynamic_beam':\n",
        "      result = run_dynamic_beam_search(example_batch=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'beam_search_ev':\n",
        "      result = beam_search_ev(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'greedy_backtrack':\n",
        "      result = greedy_backtrack_search(examples=batch, config=config, llm=llm, prm=prm)\n",
        "      print(\"Result keys:\", result.keys())\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\nFinished in {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    tokenizer = llm.get_tokenizer()\n",
        "    total_tokens = 0\n",
        "    for completion in result['completions']:\n",
        "        for comp in  completion:\n",
        "            output_tokens = tokenizer.encode(comp)\n",
        "            total_tokens += len(output_tokens)\n",
        "\n",
        "    print(f\"Total tokens in all completions: {total_tokens}\")\n",
        "\n",
        "    formatted_output = result['pred'][0].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\", \"\").strip()\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWbOqkiKPVd2"
      },
      "source": [
        "### ⏳  3.1 Comparing Thinking Time for Each Strategy\n",
        "\n",
        "Let’s compare the **thinking time** of three methods: `best_of_n`, `beam_search`, and `dvts`. Each method is evaluated using the same number of answers during the search process, measuring the time spent thinking in seconds and the number of generated tokens.\n",
        "\n",
        "In the results below, the `best_of_n` method shows the least thinking time, while the `dvts` method takes the most time. However, `best_of_n` generates more tokens due to its simpler search strategy.\n",
        "\n",
        "| **Method**      | **Number of Answers During Search** | **Thinking Time (Seconds)** | **Generated Tokens** |\n",
        "|------------------|-------------------------------------|-----------------------------|-----------------------|\n",
        "| **best_of_n**    | 8                                   | 3.54                        | 3087                  |\n",
        "| **beam_search**  | 8                                   | 10.06                       | 2049                  |\n",
        "| **dvts**         | 8                                   | 8.46                        | 2544                  |\n",
        "\n",
        "This comparison illustrates the trade-offs between the strategies, balancing time spent thinking and the complexity of the search process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ROJwROGX8q-"
      },
      "source": [
        "#### 1. **Best of n**\n",
        "\n",
        "We’ll begin by using the `best_of_n` strategy. Here’s how to track the thinking time for this method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c_fWKy5CCTLV"
      },
      "outputs": [],
      "source": [
        "question = 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$'\n",
        "\n",
        "config.n=4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK6EA32icOSk"
      },
      "outputs": [],
      "source": [
        "formatted_output = generate_with_search_and_learn(question=question, config=config, llm=llm, prm=prm, method='best_of_n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "uzKfFoKG9ejC",
        "outputId": "35bf6bb0-5afa-4de8-de80-ea4e86a1ddb0"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "## Step 1: Recall the relationship between rectangular and polar coordinates.\nThe relationship between rectangular coordinates $(x, y)$ and polar coordinates $(r, \\theta)$ is given by:\n$x = r \\cos \\theta$\n$y = r \\sin \\theta$\nWe need to find $r$ and $\\theta$ for the point $(0, 3)$.\n\n## Step 2: Calculate the radius $r$.\nUsing the first formula, we can find the value of $r$ by setting $x = 0$ and $y = 3$.\nSince $x = r \\cos \\theta$ and $y = r \\sin \\theta$, we have:\n$0 = r \\cos \\theta$\n$3 = r \\sin \\theta$\n\n## Step 3: Solve for $r$ using the equation $3 = r \\sin \\theta$.\nWe know that $\\sin^2 \\theta + \\cos^2 \\theta = 1$. Since $\\sin \\theta = 3/r$, we can substitute into this identity:\n$(3/r)^2 + \\cos^2 \\theta = 1$\n\n## Step 4: Expand the equation $(3/r)^2 + \\cos^2 \\theta = 1$.\n$(3/r)^2 + \\cos^2 \\theta = 1 \\Rightarrow 9/r^2 + \\cos^2 \\theta = 1$\n\n## Step 5: Multiply both sides by $r^2$ to clear the fraction.\n$(9/r^2) + r^2 \\cos^2 \\theta = r^2$\n\n## Step 6: Since we want $r$ in terms of $x$ and $y$, we need to use the fact that $r^2 = x^2 + y^2$. We also know that $r = \\sqrt{x^2 + y^2}$.\nWe can substitute $x = 0$ and $y = 3$ into $r^2 = x^2 + y^2$ to get:\n$r^2 = 0^2 + 3^2 = 9$\nNow we can substitute $r^2 = 9$ into the equation $(9/r^2) + r^2 \\cos^2 \\theta = r^2$:\n$(9/r^2) + 9 \\cos^2 \\theta = 9$\n\n## Step 7: Simplify the equation $(9/r^2) + 9 \\cos^2 \\theta = 9$.\nFirst, multiply both sides by $r^2$ to clear the fraction:\n$9 + 9r^2 \\cos^2 \\theta = 9r^2$\nNow subtract $9$ from both sides:\n$9r^2 \\cos^2 \\theta = 0$\n\n## Step 8: Solve for $\\cos^2 \\theta$.\nDivide both sides by $9r^2$:\n$\\cos^2 \\theta = 0$\n\n## Step 9: Find $\\theta$.\nSince $\\cos^2 \\theta = 0$, we know that $\\cos \\theta = 0$. Therefore, $\\theta = \\pi/2$.\n\n## Step 10: Substitute $\\theta = \\pi/2$ into the equation $r = \\sqrt{x^2 + y^2}$.\nSince $r^2 = x^2 + y^2$, we have:\n$r^2 = 0^2 + 3^2 = 9$\nNow substitute $r^2 = 9$ into the equation $r = \\sqrt{x^2 + y^2}$:\n$r = \\sqrt{9} = 3$\n\n## Step 11: Substitute $r = 3$ and $\\theta = \\pi/2$ into the equation $(r, \\theta)$.\nThe polar coordinates are $(r, \\theta) = (3, \\pi/2)$.\n\nThe final answer is: $\\boxed{\\left( 3, \\  \\frac{\\pi}{2}\\right)}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S9AwP5lQvUN"
      },
      "source": [
        "#### 2. **Beam Search**\n",
        "\n",
        "Now, let's try using the `beam_search` strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7CH6KN8Izp9",
        "outputId": "2f35a98b-4e0e-4b49-9e86-bf1335189ca5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beam search iterations:  10%|█         | 4/40 [03:52<34:55, 58.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finished in 232.83 seconds\n",
            "\n",
            "Total tokens in all completions: 1480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config.n=4\n",
        "# beam search specific\n",
        "config.sort_completed=True\n",
        "config.filter_duplicates=True\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(question=question, config=config, llm=llm, prm=prm, method='beam_search')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "Hw6tQD_dMwXZ",
        "outputId": "085b43e0-eaba-49d7-c2cc-0f20be809e0e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "## Step 1: Recall the conversion formulas between rectangular and polar coordinates\nThe conversion formulas between rectangular coordinates $(x, y)$ and polar coordinates $(r, \\theta)$ are given by $r = \\sqrt{x^2 + y^2}$ and $\\theta = \\arctan\\left(\\frac{y}{x}\\right)$.\n\n## Step 2: Apply the formula to convert the given point\nGiven the point $(0, 3)$, we can substitute $x = 0$ and $y = 3$ into the formula for $r$ to get $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3$.\n\n## Step 3: Calculate the angle $\\theta$ using the formula\nWe can substitute $x = 0$ and $y = 3$ into the formula for $\\theta$ to get $\\theta = \\arctan\\left(\\frac{3}{0}\\right)$. However, since $\\arctan(0)$ is undefined, we need to handle this situation. In the context of polar coordinates, when $x = 0$, the point lies on the positive $y$-axis, and $\\arctan(0)$ does not have a unique value; it's considered $\\frac{\\pi}{2}$ because it's the angle where the curve crosses the y-axis. Therefore, we have $\\theta = \\frac{\\pi}{2}$.\n\n## Step 4: Write the polar coordinates as an ordered pair\nUsing the calculated values of $r$ and $\\theta$, we can write the polar coordinates as $(3, \\frac{\\pi}{2})$.\n\nThe final answer is: $\\boxed{(3, \\frac{\\pi}{2})}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUCXmOBWLTdo"
      },
      "source": [
        "#### 2. **Beam Search with ensemble voting**\n",
        "\n",
        "I have additional implement beam search with ensemble voting stategy as independent function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk1bDcxzLTdo",
        "outputId": "ce2fe5b1-52ae-4fa5-abb6-989194b2bb47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beam search iterations:  10%|█         | 4/40 [03:47<34:04, 56.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finished in 227.19 seconds\n",
            "\n",
            "Total tokens in all completions: 1180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config.n=4 #227.19 seconds\n",
        "# beam search specific\n",
        "config.approach = 'beam_search_ev'\n",
        "config.sort_completed=True\n",
        "config.filter_duplicates=True\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(question=question, config=config, llm=llm, prm=prm, method='beam_search_ev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "7yWgjx15LTdp",
        "outputId": "ffb012ef-c296-4c23-cc83-37f4d9ef96ec"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "## Step 1: Recall the formulas for converting rectangular coordinates to polar coordinates\nThe conversion from rectangular coordinates $(x, y)$ to polar coordinates $(r, \\theta)$ can be done using the following formulas: $r = \\sqrt{x^2 + y^2}$ for the radial coordinate and $\\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right)$ for the angular coordinate.\n\n## Step 2: Calculate the radial coordinate $r$\nSubstitute $x = 0$ and $y = 3$ into the formula for $r$: $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3.$\n\n## Step 3: Calculate the angular coordinate $\\theta$\nSubstitute $x = 0$ and $y = 3$ into the formula for $\\theta$: $\\theta = \\tan^{-1}\\left(\\frac{3}{0}\\right)$. However, because the point $(0, 3)$ lies on the positive $y$-axis, the angle $\\theta$ is $\\frac{\\pi}{2}$.\n\n## Step 4: Write the polar coordinates\nTherefore, the polar coordinates of the point $(0, 3)$ are $\\left(3, \\frac{\\pi}{2}\\right)$.\n\nThe final answer is: $\\boxed{\\left(3, \\frac{\\pi}{2}\\right)}$",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxBBUd7HQzhd"
      },
      "source": [
        "#### 3. **Diverse Verifier Tree Search (DVTS)**\n",
        "\n",
        "Let's try the `dvts` strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzXW1g-dI5wN",
        "outputId": "ef78cc1a-9f92-4b10-98ca-3ba245094c49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Beam search iterations:   5%|▌         | 2/40 [01:51<35:24, 55.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finished in 111.81 seconds\n",
            "\n",
            "Total tokens in all completions: 988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "config.n=4\n",
        "# dvts specific\n",
        "config.n_beams = config.n // config.beam_width\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(question=question, config=config, llm=llm, prm=prm, method='dvts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "RGkG9MPXMvN0",
        "outputId": "5d79c103-3976-408d-aa69-4ae2eb6b2791"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Step 1:  To convert the point $(0,3)$ from rectangular coordinates to polar coordinates, we need to find the radius $r$ and the angle $heta$.\n",
              "## Step 2:  The radius $r$ can be found using the formula $r = \\sqrt{x^2 + y^2}$. In this case, $x = 0$ and $y = 3$, so $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3$.\n",
              "## Step 3:  Next, we need to find the angle $heta$. The angle $heta$ can be found using the formula $heta = \\arctan\\left(\\frac{y}{x}\\right)$. However, since $x = 0$, the value of $heta$ will be $\\frac{\\pi}{2}$.\n",
              "## Step 4:  So, we have found the polar coordinates $(r, heta)$ to be $(3, \\frac{\\pi}{2})$.\n",
              "\n",
              "The final answer is: $\\boxed{\\left(3, \\frac{\\pi}{2}\\right)}$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9FmC6GyodUo"
      },
      "source": [
        "#### 4. **Dynamic Beam Search Method**\n",
        "\n",
        "Let's try our new `Dynamic Beam search` strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwhIqIGJoq1_",
        "outputId": "17ac700f-f206-47c9-a8d3-e0816d8b332b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dynamic Beam Search Steps:  50%|█████     | 5/10 [05:40<05:40, 68.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Finished in 340.65 seconds\n",
            "\n",
            "Total tokens in all completions: 1436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# setting basic parameter\n",
        "config.n = 4\n",
        "\n",
        "# dynamic beam search parameters\n",
        "config.approach = \"dynamic_beam\"\n",
        "config.sort_completed = True\n",
        "config.filter_duplicates = True\n",
        "config.num_iterations = 10\n",
        "config.dynamic_beam_delta = 0.3   # Beam score margin\n",
        "config.min_beams = 2\n",
        "config.max_beams = 4\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(\n",
        "    question=question,\n",
        "    config=config,\n",
        "    llm=llm,\n",
        "    prm=prm,\n",
        "    method=\"dynamic_beam\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "-28ZfVzDo2h2",
        "outputId": "4c699d4f-4ef5-4948-ad81-e1b585d9e752"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Step 1: Recall the conversion formulas from rectangular coordinates to polar coordinates.\nThe conversion formulas are $r = \\sqrt{x^2 + y^2}$ for the radial coordinate and $\\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right)$ for the angular coordinate.\n\n## Step 2: Substitute the given rectangular coordinates $(0,3)$ into the formula for the radial coordinate $r$.\nSince $x = 0$ and $y = 3$, we have $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3$.\n\n## Step 3: Substitute the given rectangular coordinates $(0,3)$ into the formula for the angular coordinate $\\theta$.\nWe have $\\theta = \\tan^{-1}\\left(\\frac{3}{0}\\right)$. However, since $\\tan^{-1}(0)$ is undefined, we need to use a different approach to find the correct angle.\n\n## Step 4: Use the fact that $\\tan^{-1}(0) = \\frac{\\pi}{2}$ to find the correct angle.\nSince the point $(0,3)$ lies in the first quadrant, the correct angle is $\\theta = \\frac{\\pi}{2}$.\n\n## Step 5: Write down the polar coordinates of the point $(0,3)$.\nWe have $(r, \\theta) = \\left(3, \\frac{\\pi}{2}\\right)$.\n\nThe final answer is: $\\boxed{\\left(3, \\frac{\\pi}{2}\\right)}$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKQUUy9yLTdt"
      },
      "source": [
        "#### 4. **Greedy Backtrack Search Method**\n",
        "\n",
        "Let's try our new `Greedy Backtrack Search` strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6zXvIcsLTdt",
        "outputId": "956322db-fe0e-4aea-e1d2-1ed6ac5ea71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:  10%|█         | 1/10 [00:58<08:44, 58.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:  20%|██        | 2/10 [02:03<08:17, 62.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:  30%|███       | 3/10 [03:16<07:51, 67.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:  40%|████      | 4/10 [05:24<09:06, 91.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "new_beam.stop_reasons:  ['EOS']\n",
            "new_beam.stop_reasons:  ['\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGreedy Backtracking Search:  40%|████      | 4/10 [07:46<11:39, 116.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_beam.stop_reasons:  ['\\n\\n']\n",
            "Result keys: dict_keys(['completions', 'pred', 'completion_tokens', 'scores'])\n",
            "\n",
            "Finished in 466.06 seconds\n",
            "\n",
            "Total tokens in all completions: 2772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sal.search import greedy_backtrack_search\n",
        "\n",
        "# n=2, depth=2, res='' <- no result\n",
        "# n=2, depth=3, it works!!!\n",
        "# n=4, depth=2, res='', 1068.20 seconds\n",
        "# n=4, depth=3, it works!!! 457.16 seconds\n",
        "# n=4, depth=4, works, 457.96 seconds\n",
        "# n=4, depth=5, works, 466.06 seconds\n",
        "\n",
        "# setting basic parameter\n",
        "config.n = 4\n",
        "\n",
        "# dynamic beam search parameters\n",
        "config.approach = \"greedy_backtrack\"\n",
        "config.sort_completed = True\n",
        "config.filter_duplicates = True\n",
        "config.num_iterations = 10\n",
        "config.max_backtrack_depth = 3         # (NEW) maximum levels to look back, default=3\n",
        "config.early_stop_when_x_finished = 1\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(\n",
        "    question=question,\n",
        "    config=config,\n",
        "    llm=llm,\n",
        "    prm=prm,\n",
        "    method=\"greedy_backtrack\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HDGHkRE_LTdu",
        "outputId": "bbace2ac-96dd-425f-8543-ffe35cc852bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Step 1:  To convert the point $(0,3)$ from rectangular coordinates to polar coordinates, we need to calculate the radius $r$ and the angle $heta$.\n## Step 2:  First, let's recall the formulas to calculate the radius $r$ and the angle $heta$ in polar coordinates. The radius $r = \\sqrt{x^2 + y^2}$, where $x$ and $y$ are the rectangular coordinates, and the angle $heta = \\tan^{-1}\\left(\\frac{y}{x}\\right)$.\n## Step 3:  Substituting the given rectangular coordinates $(0,3)$, we can calculate the radius $r$. Here, $x = 0$ and $y = 3$, so $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3$.\n## Step 4:  Next, we can calculate the angle $heta$. For this point, $x = 0$ and $y = 3$, which means the point lies on the positive $y$-axis. Since the point is not on the positive $x$-axis, the angle $heta$ will be $\\frac{\\pi}{2}$, as the point lies exactly on the positive $y$-axis, making a $90^\\circ$ or $\\frac{\\pi}{2}$ angle with the positive $x$-axis.\n## Step 5:  Therefore, we have found that the polar coordinates of the point $(0,3)$ are $\\left(3,\\frac{\\pi}{2}\\right)$.\n\n## Step 1:  To convert the point $(0,3)$ from rectangular coordinates to polar coordinates, we need to calculate the radius $r$ and the angle $heta$.\n## Step 2:  First, let's recall the formulas to calculate the radius $r$ and the angle $heta$ in polar coordinates. The radius $r = \\sqrt{x^2 + y^2}$, where $x$ and $y$ are the rectangular coordinates, and the angle $heta = \\tan^{-1}\\left(\\frac{y}{x}\\right)$.\n## Step 3:  Substituting the given rectangular coordinates $(0,3)$, we can calculate the radius $r$. Here, $x = 0$ and $y = 3$, so $r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3$.\n## Step 4:  Next, we can calculate the angle $heta$. For this point, $x = 0$ and $y = 3$, which means the point lies on the positive $y$-axis. Since the point is not on the positive $x$-axis, the angle $heta$ will be $\\frac{\\pi}{2}$, as the point lies exactly on the positive $y$-axis, making a $90^\\circ$ or $\\frac{\\pi}{2}$ angle with the positive $x$-axis.\n## Step 5:  Therefore, we have found that the polar coordinates of the point $(0,3)$ are $\\left(3,\\frac{\\pi}{2}\\right)$."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PM9HHwBSYWk"
      },
      "source": [
        "### 🙋 3.2 Testing the System with a Simple Question\n",
        "\n",
        "In this final example, we’ll test the system using a straightforward question to observe how it performs in simpler cases. This allows us to verify that the system works as expected even for basic queries.\n",
        "\n",
        "Let's try the following question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq9vM1uRM7A8",
        "outputId": "3c192fa7-8eee-4dd3-ea96-f2fbe7cae398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finished in 45.39 seconds\n",
            "\n",
            "Total tokens in all completions: 32\n"
          ]
        }
      ],
      "source": [
        "question = 'What\\'s the capital of Spain?'\n",
        "\n",
        "config.n=4\n",
        "\n",
        "formatted_output = generate_with_search_and_learn(question=question, config=config, llm=llm, prm=prm, method='best_of_n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "ysfR0nPfM-Ub",
        "outputId": "0ce8246e-56b9-4d61-c300-cdc3c8bd2129"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The capital of Spain is Madrid."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(formatted_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgdeSegeANoT"
      },
      "source": [
        "Even though we set a larger number of candidate answers (`N`), the time spent thinking remains relatively small (1.03 seconds and 544 generated tokens). This demonstrates the system’s ability to efficiently handle easier problems, spending less time on them, while leveraging its enhanced capabilities for more complex questions.\n",
        "\n",
        "🏆 **We now have a fully operational pipeline** that leverages test-time compute, enabling the system to \"think longer\" for more complicated queries, while also maintaining fast response times for straightforward questions.\n",
        "\n",
        "This approach ensures the system can scale its thinking time based on the task's complexity, offering an efficient and responsive solution for both simple and challenging problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92znAyJ0AOPY"
      },
      "source": [
        "## 4. Continuing the Journey and Resources 🧑‍🎓️\n",
        "\n",
        "If you're eager to continue exploring, be sure to check out the original experimental [blog](https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute) and all the references mentioned within it. These resources will deepen your understanding of test-time compute, its benefits, and its applications in LLMs.\n",
        "\n",
        "\n",
        "Happy learning and experimenting! 🚀"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2551e3c25d0c4d83b90e6ebc7a320846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2a245e39189e47c58bc046527600db2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_2551e3c25d0c4d83b90e6ebc7a320846"
          }
        },
        "894920f5f4364f42bacff410bd38a8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dc243152932471e8f8d29c91499e84b",
              "IPY_MODEL_2c85d529894847d080f2e8e4dc87a3a5",
              "IPY_MODEL_408aac5d48174285b672900f2629847c"
            ],
            "layout": "IPY_MODEL_c374c51afa8e4e239f25999c718d5445"
          }
        },
        "6dc243152932471e8f8d29c91499e84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbec446655044d629512c9aaea7a2b99",
            "placeholder": "​",
            "style": "IPY_MODEL_94171bd013df416894f7386023bb8908",
            "value": ""
          }
        },
        "2c85d529894847d080f2e8e4dc87a3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e62a13cd394334968f35e823f00209",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25292ad9fa874a0d9638eb3cedc77f8a",
            "value": 1
          }
        },
        "408aac5d48174285b672900f2629847c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f896e2e50530412f81852108c075a69c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8842cbfa76d435db3f7cdb651bb3a28",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15&lt;00:00, 15.27s/it]\n"
          }
        },
        "c374c51afa8e4e239f25999c718d5445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbec446655044d629512c9aaea7a2b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94171bd013df416894f7386023bb8908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e62a13cd394334968f35e823f00209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25292ad9fa874a0d9638eb3cedc77f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f896e2e50530412f81852108c075a69c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8842cbfa76d435db3f7cdb651bb3a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7219feb2e64fe6a94e7e057a5e3f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0f1b5ce6e245a4b3b5bd8151d1046e",
              "IPY_MODEL_05be7fc29f5e4aa3ae607afd5206acd5",
              "IPY_MODEL_b7aab0419ce74bb7b8a93fc9c21efbb3"
            ],
            "layout": "IPY_MODEL_af0a03e44d774557aaf775ade950d2c9"
          }
        },
        "6e0f1b5ce6e245a4b3b5bd8151d1046e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a80ac8049f48498655b523e6d953e6",
            "placeholder": "​",
            "style": "IPY_MODEL_c7e46a287450489d880a3e188d74a1ce",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "05be7fc29f5e4aa3ae607afd5206acd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a19c51484a648e684393d3138b91456",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cf216fb160749728dcd26f97164cc1f",
            "value": 4
          }
        },
        "b7aab0419ce74bb7b8a93fc9c21efbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a59194d3f248a9a3a6133aa037c5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_e5906a6dcc4e41f78bd44d64e34b5334",
            "value": " 4/4 [00:42&lt;00:00, 19.85s/it]"
          }
        },
        "af0a03e44d774557aaf775ade950d2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a80ac8049f48498655b523e6d953e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e46a287450489d880a3e188d74a1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a19c51484a648e684393d3138b91456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf216fb160749728dcd26f97164cc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80a59194d3f248a9a3a6133aa037c5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5906a6dcc4e41f78bd44d64e34b5334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}