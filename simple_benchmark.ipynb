{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xctusmJ6BZ6_"
      },
      "source": [
        "# Scaling Test-Time Compute for Longer Thinking in LLMs\n",
        "\n",
        "## Simple Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZEK_vIk22A"
      },
      "source": [
        "How to run:\n",
        "- Set Hugging Face Token\n",
        "- Use T4\n",
        "- Run all\n",
        "\n",
        "Will encounter errors at two points:\n",
        "1. After `pip install`\n",
        "2. On the first attempt to `import sal`\n",
        "\n",
        "Just ‚ÄúRestart session and run all‚Äù after each of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy8xg9GLs5jy"
      },
      "source": [
        "‚ùóÔ∏èHuge amount of time is needed for `pip install` and downloading models in every new RUNTIME. If any error occurs, restart the SESSION."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-A5IE6tQpqt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fECoFgZ8SUxU"
      },
      "outputs": [],
      "source": [
        "methods = [\n",
        "    'best_of_n',\n",
        "    'beam_search',\n",
        "    'dvts',\n",
        "    'dynamic_beam', # 3\n",
        "    'beam_search_ev', # 4\n",
        "    'greedy_backtrack' # 5\n",
        "]\n",
        "\n",
        "# Set method to be tested\n",
        "test_method = methods[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twKCzVIg71Xa"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKdHzQUXGjAh"
      },
      "source": [
        "Since Colab comes with many pre-installed packages, leading to difficult-to-resolve version conflicts, we install dependencies in a local virtual environment and freeze them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vniSZihLpl0y"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo \"\n",
        "accelerate==1.5.2\n",
        "aiohappyeyeballs==2.6.1\n",
        "aiohttp==3.11.14\n",
        "aiosignal==1.3.2\n",
        "annotated-types==0.7.0\n",
        "antlr4-python3-runtime==4.7.2\n",
        "anyio==4.9.0\n",
        "attrs==25.3.0\n",
        "certifi==2025.1.31\n",
        "charset-normalizer==3.4.1\n",
        "click==8.1.8\n",
        "cloudpickle==3.1.1\n",
        "datasets==3.5.0\n",
        "dill==0.3.8\n",
        "diskcache==5.6.3\n",
        "distro==1.9.0\n",
        "einops==0.8.1\n",
        "fastapi==0.115.12\n",
        "filelock==3.18.0\n",
        "frozenlist==1.5.0\n",
        "fsspec==2024.12.0\n",
        "gguf==0.10.0\n",
        "h11==0.14.0\n",
        "hf_transfer==0.1.9\n",
        "httpcore==1.0.7\n",
        "httptools==0.6.4\n",
        "httpx==0.28.1\n",
        "huggingface-hub==0.29.3\n",
        "idna==3.10\n",
        "importlib_metadata==8.6.1\n",
        "iniconfig==2.1.0\n",
        "interegular==0.3.3\n",
        "isort==6.0.1\n",
        "Jinja2==3.1.6\n",
        "jiter==0.9.0\n",
        "jsonschema==4.23.0\n",
        "jsonschema-specifications==2024.10.1\n",
        "lark==1.2.2\n",
        "latex2sympy2==1.9.1\n",
        "llvmlite==0.44.0\n",
        "lm-format-enforcer==0.10.6\n",
        "MarkupSafe==3.0.2\n",
        "mistral_common==1.5.4\n",
        "mpmath==1.3.0\n",
        "msgpack==1.1.0\n",
        "msgspec==0.19.0\n",
        "multidict==6.2.0\n",
        "multiprocess==0.70.16\n",
        "nest-asyncio==1.6.0\n",
        "networkx==3.4.2\n",
        "numba==0.61.0\n",
        "numpy==1.26.4\n",
        "nvidia-ml-py==12.570.86\n",
        "openai==1.69.0\n",
        "opencv-python-headless==4.11.0.86\n",
        "outlines==0.0.46\n",
        "packaging==24.2\n",
        "pandas==2.2.3\n",
        "partial-json-parser==0.2.1.1.post5\n",
        "Pebble==5.1.1\n",
        "pillow==11.1.0\n",
        "pluggy==1.5.0\n",
        "prometheus-fastapi-instrumentator==7.1.0\n",
        "prometheus_client==0.21.1\n",
        "propcache==0.3.1\n",
        "protobuf==6.30.2\n",
        "psutil==7.0.0\n",
        "py-cpuinfo==9.0.0\n",
        "pyairports==2.1.1\n",
        "pyarrow==19.0.1\n",
        "pycountry==24.6.1\n",
        "pydantic==2.11.1\n",
        "pydantic_core==2.33.0\n",
        "pytest==8.3.5\n",
        "python-dateutil==2.9.0.post0\n",
        "python-dotenv==1.1.0\n",
        "pytz==2025.2\n",
        "PyYAML==6.0.2\n",
        "pyzmq==26.3.0\n",
        "ray==2.44.1\n",
        "referencing==0.36.2\n",
        "regex==2024.11.6\n",
        "requests==2.32.3\n",
        "rpds-py==0.24.0\n",
        "ruff==0.11.2\n",
        "safetensors==0.5.3\n",
        "sentencepiece==0.2.0\n",
        "six==1.17.0\n",
        "sniffio==1.3.1\n",
        "starlette==0.46.1\n",
        "sympy==1.13.3\n",
        "tiktoken==0.9.0\n",
        "tokenizers==0.21.1\n",
        "torch==2.4.0\n",
        "torchvision==0.19.0\n",
        "tqdm==4.67.1\n",
        "transformers==4.50.3\n",
        "typing-inspection==0.4.0\n",
        "typing_extensions==4.13.0\n",
        "tzdata==2025.2\n",
        "urllib3==2.3.0\n",
        "uvicorn==0.34.0\n",
        "uvloop==0.21.0\n",
        "vllm==0.6.3\n",
        "watchfiles==1.0.4\n",
        "websockets==15.0.1\n",
        "word2number==1.1\n",
        "xxhash==3.5.0\n",
        "yarl==1.18.3\n",
        "zipp==3.21.0\n",
        "\" > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0XO0VwIHQyx"
      },
      "source": [
        "‚ùóÔ∏èThis ends with multiple errors; just ignore them, as we are not using those packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Uhn86fNFtw0"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0YDC2_7XTm8"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/choyerhuang/CSCI544-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLExGBclx8PK"
      },
      "source": [
        "‚ùóÔ∏èIf `ImportError: No module named sal`, restart session and start again from here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT3jH_d_XcEb"
      },
      "outputs": [],
      "source": [
        "%cd /content/CSCI544-Project\n",
        "!pip install -e '.[dev]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQHu9T176zh"
      },
      "source": [
        "Log in to Hugging Face to access [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct), as it is a gated model! üóùÔ∏è  \n",
        "If you haven't previously requested access, you'll need to submit a request before proceeding.\n",
        "\n",
        "‚ö†Ô∏è Use your USC email to register an account. When requesting access, enter \"University of Southern California\" as your affiliation and select \"Research Graduate\"; otherwise, your request will be rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnEaTlFYZF_H"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX07zCTA8MWL"
      },
      "source": [
        "## 2. Setup the Large Language Model (LLM) and the Process Reward Model (PRM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L42axgg1uE-n"
      },
      "source": [
        "‚¨áÔ∏è Start again from here after **Restart session**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG1MolfxmZ7M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from vllm import LLM\n",
        "from sal.models.reward_models import RLHFFlow\n",
        "\n",
        "model_path=\"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "prm_path=\"RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\"\n",
        "\n",
        "llm = LLM(\n",
        "    model=model_path,\n",
        "    gpu_memory_utilization=0.5,  # Utilize 50% of GPU memory\n",
        "    enable_prefix_caching=True,  # Optimize repeated prefix computations\n",
        "    seed=42,                     # Set seed for reproducibility\n",
        "    dtype='half',\n",
        "    max_model_len=8192,\n",
        ")\n",
        "\n",
        "prm = RLHFFlow(prm_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f703FSz35ybL"
      },
      "source": [
        "## 3. Setup Searching Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6s6GS16QZLV"
      },
      "outputs": [],
      "source": [
        "from sal.config import Config\n",
        "import os\n",
        "os.chdir('/content/CSCI544-Project')\n",
        "from sal.search import beam_search, best_of_n, dvts, run_dynamic_beam_search, beam_search_ev, greedy_backtrack_search\n",
        "\n",
        "config = Config()\n",
        "\n",
        "config.n=4\n",
        "config.prm_batch_size=1\n",
        "config.search_batch_size=1\n",
        "\n",
        "if test_method == 'beam_search':\n",
        "  config.sort_completed=True\n",
        "  config.filter_duplicates=True\n",
        "elif test_method == 'dvts':\n",
        "  config.sort_completed=True\n",
        "  config.filter_duplicates=True\n",
        "  config.n_beams = config.n // config.beam_width\n",
        "elif test_method == 'dynamic_beam':\n",
        "  config.approach = \"dynamic_beam\"\n",
        "  config.sort_completed = True\n",
        "  config.filter_duplicates = True\n",
        "  config.num_iterations = 7\n",
        "  config.dynamic_beam_delta = 0.3   # Beam score margin\n",
        "  config.min_beams = 2\n",
        "  config.max_beams = 4\n",
        "elif test_method == 'beam_search_ev':\n",
        "  config.approach = 'beam_search_ev'\n",
        "  config.sort_completed=True\n",
        "  config.filter_duplicates=True\n",
        "elif test_method == 'greedy_backtrack':\n",
        "  config.approach = \"greedy_backtrack\"\n",
        "  config.sort_completed = True\n",
        "  config.filter_duplicates = True\n",
        "  config.num_iterations = 10\n",
        "  config.max_backtrack_depth = 3\n",
        "  config.early_stop_when_x_finished = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpswbcVi37KR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def generate_with_search_and_learn(question, config, llm, prm, method='best_of_n'):\n",
        "    \"\"\"\n",
        "    Generate an answer for a given question using the search-and-learn pipeline.\n",
        "\n",
        "    Args:\n",
        "    - question (str): The input question to generate an answer for.\n",
        "    - config (Config): Configuration object containing parameters for search strategy.\n",
        "    - llm (LLM): Pretrained large language model used for generating answers.\n",
        "    - prm (RLHFFlow): Process reward model used for evaluating answers.\n",
        "    - method (str): Search strategy to use. Options are 'best_of_n', 'beam_search', 'dvts'. Default is 'best_of_n'.\n",
        "\n",
        "    Returns:\n",
        "    - str: The formatted output after processing the question.\n",
        "    \"\"\"\n",
        "    batch = {\"problem\": [question]}\n",
        "\n",
        "    start_time = time.time()\n",
        "    if method == 'best_of_n':\n",
        "      result = best_of_n(x=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'beam_search':\n",
        "      result = beam_search(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'dvts':\n",
        "      result = dvts(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'dynamic_beam':\n",
        "      result = run_dynamic_beam_search(example_batch=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'beam_search_ev':\n",
        "      result = beam_search_ev(examples=batch, config=config, llm=llm, prm=prm)\n",
        "    elif method == 'greedy_backtrack':\n",
        "      result = greedy_backtrack_search(examples=batch, config=config, llm=llm, prm=prm)\n",
        "      print(\"Result keys:\", result.keys())\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\nFinished in {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    # tokenizer = llm.get_tokenizer()\n",
        "    # total_tokens = 0\n",
        "    # for completion in result['completions']:\n",
        "    #     for comp in  completion:\n",
        "    #         output_tokens = tokenizer.encode(comp)\n",
        "    #         total_tokens += len(output_tokens)\n",
        "\n",
        "    # print(f\"Total tokens in all completions: {total_tokens}\")\n",
        "\n",
        "    formatted_output = result['pred'][0].replace(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\", \"\").strip()\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUu3HbdjK44j"
      },
      "source": [
        "## 4. Load & Run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FMcNDZ1LCSb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "math_500_path = \"/content/CSCI544-Project/math_500.json\"\n",
        "sample_100_path = \"/content/CSCI544-Project/sample_100.json\"\n",
        "\n",
        "with open(math_500_path, \"r\") as f:\n",
        "    math_500_data = json.load(f)\n",
        "\n",
        "with open(sample_100_path, \"r\") as f:\n",
        "    sample_100_id = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_fWKy5CCTLV"
      },
      "outputs": [],
      "source": [
        "output_file_path = f\"/content/gdrive/MyDrive/csci544_output_{test_method}.jsonl\"\n",
        "\n",
        "try:\n",
        "    # Read the last written idx from the file, if it exists\n",
        "    with open(output_file_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        last_idx = int(json.loads(lines[-1])[\"sample_idx\"]) if lines else -1\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, start from 0\n",
        "    last_idx = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O6h-eW1LwXe"
      },
      "outputs": [],
      "source": [
        "print(\"start time: \" + time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(time.mktime(time.gmtime()) + -7 * 3600)) + \" PDT\")\n",
        "\n",
        "with open(output_file_path, \"a\") as output_file:\n",
        "    for idx, id in enumerate(sample_100_id):\n",
        "        if idx <= last_idx:\n",
        "            continue\n",
        "\n",
        "        for row in math_500_data[\"rows\"]:\n",
        "            if row[\"row\"][\"unique_id\"] == id:\n",
        "                curr_row = row[\"row\"]\n",
        "                print(f\"sample_idx: {idx} - unique_id: {id}\")\n",
        "                break\n",
        "        else:\n",
        "            print(f\"sample_idx: {idx} - unique_id: {id} not found in math_500.json\")\n",
        "            continue\n",
        "\n",
        "        formatted_output = generate_with_search_and_learn(\n",
        "            question=curr_row[\"problem\"],\n",
        "            config=config,\n",
        "            llm=llm,\n",
        "            prm=prm,\n",
        "            method=test_method\n",
        "        )\n",
        "\n",
        "        output_file.write(json.dumps({\n",
        "            \"sample_idx\": idx,\n",
        "            \"level\": curr_row[\"level\"],\n",
        "            \"unique_id\": curr_row[\"unique_id\"],\n",
        "            \"predict\": formatted_output,\n",
        "            \"answer\": curr_row[\"answer\"],\n",
        "            \"correct\": 0\n",
        "        }) + \"\\n\")\n",
        "        output_file.flush()\n",
        "\n",
        "print(\"end time: \" + time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(time.mktime(time.gmtime()) + -7 * 3600)) + \" PDT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajomhl_CG01J"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import display, Markdown\n",
        "\n",
        "# display(Markdown(formatted_output))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
